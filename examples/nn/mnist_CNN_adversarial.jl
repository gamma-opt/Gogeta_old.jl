using Logging
using Statistics
using Flux
using Flux: onehotbatch, logitcrossentropy, train!
using MLDatasets
using MLDatasets: MNIST
using ML_as_MO

# include("../src/nn/CNN_JuMP_model.jl") # REMOVE THIS WHEN ADDED TO PACKAGE
# location of the create_CNN_adv function
include("helper_functions.jl")

@info "Creating and training a small ReLU CNN using Flux.jl based on the MNIST digit dataset"

x_train, y_train = MNIST(split=:train)[:]
x_test, y_test = MNIST(split=:test)[:]

x_train = reshape(x_train, 28, 28, 1, 60000)
x_test = reshape(x_test, 28, 28, 1, 10000)

y_train_oh = onehotbatch(y_train, 0:9)

train = [(x_train, y_train_oh)]
test = [(x_test, y_test)]

model = Chain(
    Conv((5,5), 1=>4, relu),
    MaxPool((2,2)),
    Flux.flatten,
    Dense(576, 16, relu),
    Dense(16, 10),
)

p = Flux.params(model)
loss(x, y) = logitcrossentropy(model(x), y)
opt = Adam(0.01)

@info "Training the CNN for 50 cycles with the full training set and printing its accuracy on the test set"

# training the CNN
n = 50
loss_values = zeros(n)
for i in 1:n
    train!(loss, p, train, opt)
    loss_values[i] = loss(x_train, y_train_oh)
    if i % 5 == 0
        println("Training cycle $i, loss value $(loss_values[i])")
    end
end

# calculating the accuracy of the CNN (around 95% with these training parameters)
correct_guesses = 0
test_len = length(y_test)
for i in 1:test_len
    if findmax(model(reshape(x_test[:,:,:,i], 28, 28, 1, 1)))[2][1] - 1  == y_test[i] # -1 to get right index
        correct_guesses += 1
    end
end
acc = correct_guesses / test_len
println("Accuracy of the CNN: $(acc)%")

@info "Creating a MILP model and generating one adversarial image based on the trained ReLU CNN.
       The adversarial image is generated by minimising the L1-norm difference between the original
       and the adversarial image such that the output node corresponging to the adversarial label
       has a 20% bigger value than in all other output nodes. Here, we require than an image of the
       digit 5 is missclassified as the digit 0. A timelimit of 600 sec is used. 
       (L2-norm can also be used but this requires larger computational time to give a solution)"

# big-M values used for constraint bounds in the MILP
L_bounds = Vector{Array{Float32}}(undef, length(model))
U_bounds = Vector{Array{Float32}}(undef, length(model))

L_bounds[1] = fill(0, (1,28,28));     U_bounds[1] = fill(1, (1,28,28))
L_bounds[2] = fill(-1000, (4,24,24)); U_bounds[2] = fill(1000, (4,24,24))
L_bounds[3] = fill(-1000, (4,12,12)); U_bounds[3] = fill(1000, (4,12,12))
L_bounds[4] = fill(-1000, (16,1,1));  U_bounds[4] = fill(1000, (16,1,1))
L_bounds[5] = fill(-1000, (10,1,1));  U_bounds[5] = fill(1000, (10,1,1))

# the idx-th training image is used (train set index 1 is a image of 5, its adversarial couterpart is an image of a 0)
# NOTE! there is no guarantee of finding an optimal solution within the set timelimit below, if an error
# "Result index of attribute MathOptInterface.VariablePrimal(1) out of bounds. There are currently 0 solution(s) in the model."
# is thrown, try a larger timelimit in the function create_CNN_adv
idx = 1
time, adv = create_CNN_adv(model, idx, "MNIST", L_bounds, U_bounds, 600, true, "L1")

# the digit guess of the idx-th training image and the adversarial image
CNN_guess_orig = argmax(model(reshape(x_train[:,:,:,idx], 28, 28, 1, 1)))[1]-1
CNN_guess_adv = argmax(model(reshape(adv, 28, 28, 1, 1)))[1]-1
println("Original training image guess: $CNN_guess_orig, adversarial image guess: $CNN_guess_adv")

@info "Here we display the original image and its adversarial counterpart"

# display the original training image and its adversarial counterpart
convert2image(MNIST, reshape(x_train[:,:,:,idx], 28, 28))
convert2image(MNIST, reshape(adv, 28, 28))
